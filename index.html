
<script src="https://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<!-- css file modified from https://taesung.me/SwappingAutoencoder/ -->
<style type="text/css">
  body {
    font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1000px;
  }
  h1 {
    font-weight:300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
    0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
    5px 5px 0 0px #fff, /* The second layer */
    5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
    10px 10px 0 0px #fff, /* The third layer */
    10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
    15px 15px 0 0px #fff, /* The fourth layer */
    15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
    20px 20px 0 0px #fff, /* The fifth layer */
    20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
    25px 25px 0 0px #fff, /* The fifth layer */
    25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }

  .paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
    0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

    margin-left: 10px;
    margin-right: 45px;
  }

  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
    0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
    5px 5px 0 0px #fff, /* The second layer */
    5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
    10px 10px 0 0px #fff, /* The third layer */
    10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
    top: 50%;
    transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

<!-- ----------------------------------------------------------------------------- -->

<html>

  <!-- ----------------------------------------------------------------------------- -->

  <head>
    <title>CVPR 2022 Tutorial: Towards always-on egocentric vision research using Meta’s Aria glasses</title>
    <meta property="og:image" content="" />
    <meta property="og:title" content="CVPR 2022 Tutorial: Towards always-on egocentric vision research using Meta’s Aria glasses" />
  </head>

  <!-- ----------------------------------------------------------------------------- -->

  <body>
    <br>
    <!-- <center> -->
      <center><span style="font-size:45px">CVPR 2022 Tutorial: Towards always-on egocentric vision research using Meta’s Aria glasses</span></center>
      <br>
      <center><span style="font-size:25px">19 June 2022, afternoon session</span></center>
      <br>
      <center><img src="./resources/project_aria.jpeg" width="500"></center></br>

      <table align=center width=900px>
        <tr>
          <td align=center width=250px>
            <span style="font-size:20px"><a href="https://scholar.google.co.uk/citations?user=MhowvPkAAAAJ&hl=en">Richard Newcombe</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;
            <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=fSb94nAAAAAJ&hl=en">Zhaoyang Lv</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;<span style="font-size:20px"><a href="https://scholar.google.co.uk/citations?user=h-CpQGgAAAAJ&hl=en">Chris Sweeney</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;<br>
            <span style="font-size:20px"><a href="https://scholar.google.fr/citations?user=8u1nmVUAAAAJ&hl=en">Pierre Moulon</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;  
            <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=ndOMZXMAAAAJ&hl=en">Jakob Engel</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;
            <span style="font-size:20px"><a href="https://www.linkedin.com/in/guptaprince">Prince Gupta</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;
            <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=rCw-l7oAAAAJ&hl=en">Hyo Jin Kim</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;
            <span style="font-size:20px"><a href="https://scholar.google.de/citations?user=49_cCT8AAAAJ&hl=en">Julian Straub</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;<br>
            <span style="font-size:20px"><a href="https://www.linkedin.com/in/georgesberenger/">Georges Berenger</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;
            <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=USWXJqcAAAAJ&hl=en">Armin Alaghi</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;          
            <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=yv3sH74AAAAJ&hl=en">Kris Kitani</a><sup>2</sup></span>&nbsp;&nbsp;&nbsp;  
            <span style="font-size:20px"><a href="https://scholar.google.com/citations?user=R3eSzv0AAAAJ&hl=en">Vivek Roy</a><sup>2</sup></span> 
          </td>
        </tr>
      </table>

      <table align=center width=1000px>
        <tr>
          <td align=center width=100px>
            <center>
              <span style="font-size:20px"></span>
            </center>
          </td>
          <td align=center width=400px>
            <center>
              <span style="font-size:20px"><sup>1</sup>Meta Reality Labs Research</span>
            </center>
          </td>
          <td align=center width=400px>
            <center>
              <span style="font-size:20px"><sup>2</sup>Carnegie Melon University</span>
            </center>
          </td>
          <td align=center width=100px>
            <center>
              <span style="font-size:20px"></span>
            </center>
          </td>
        </tr>
      </table>

      <center>
      <table>
        <tr>
          <td style="vertical-align:bottom" width=200px> <span style="font-size:15pt">
            <center>
              [Dataset Link TBC]
            </center>
          </td>
          <td style="vertical-align:bottom" width=200px> <span style="font-size:15pt">
            <center>
              [Tooling Link TBC]
            </center>
          </td>
          <td style="vertical-align:bottom" width=200px> <span style="font-size:15pt">
            <center>
              [Paper Link TBC]
            </center>
          </td>
        </tr>
      </table>
      </center>

      <br>
      <hr>

    <!-- ----------------------------------------------------------------------------- -->

    <table align=center width=900px>
      <center><h2>Abstract</h2></center>
      <tr>
        <a href="https://about.facebook.com/realitylabs/projectaria/" target="_blank">Project Aria</a> is a research device that is worn like a regular pair of glasses, for researchers to study the future of computer vision with always-on sensing. Sensors on Project Aria capture egocentric video and audio, in addition to eye-gaze, inertial, and location information. On-device compute power is used to encrypt and store information that, when uploaded to separate designated back-end storage, helps researchers build the capabilities necessary for AR to work in the real world.<br> <br>

        Meta is building an academic program to enable researchers to use Aria devices for academic research. Researchers will receive Aria glasses as well as access to associated machine perception services upon request.<br> <br>

        In this tutorial, we will introduce researchers through the Aria research program, including tutorials about how partners can capture and consume data with Aria hardware and services. We will also share open datasets captured with Aria, to enable researchers to accelerate research on always-on egocentric vision.
        <br>
      </tr>
      <br>

      <hr>

          <!-- ----------------------------------------------------------------------------- -->

    <table align=center width=900px>
      <center><h2>Agenda</h2></center>
      <tr>
        <p style="text-align: center;">SECTION ONE: An Introduction to Project Aria</p>

        13:30 Motivation and Overview of Project Aria, by Richard Newcombe

        <p style="text-align: center;">SECTION TWO: Aria for Universities</p>

        13:45 Introducing Aria Data and Tooling, by Zhaoyang Lv</br>

        14:05 Introducing VRS Format, by Georges Berenger</br>

        14:20 Overview of Aria Research Kit (ARK), by Pierre Moulon</br>

        14:35 Q&A on working with Aria, by Prince Gupta</br>

        14:45 BREAK</br>
        
        <p style="text-align: center;">SECTION THREE: Aria in Research</p>

        15:15 Aria for Location, by Jakob Engel</br>

        15:35 Aria for Objects, by Julian Straub and Chris Sweeney</br>

        15:55 Aria Hardware, by Armin Alaghi</br>

        16:15 Aria for Privacy, by Hyo Jin Kim</br>

        16:35 Partner Highlights: Multi-sensor localization for Indoor Navigation, by Kris Kitani</br>

        <p style="text-align: center;">SECTION FOUR: Closing remarks</p>

        16:40 Closing Remarks & Joint Q&A
        </br>
      </tr>
      <br>

      <hr>

    <!-- ----------------------------------------------------------------------------- -->

      <center><h2>Questions?</h2></center>

      <table align=center width=900px>
        <tr>
          Visit the <a href="https://about.facebook.com/realitylabs/projectaria/" target="_blank">Project Aria website</a> or email <a href="mailto:projectaria@fb.com">projectaria@fb.com</a> to get more information on the project.</br></br>

          Academic and industrial research institutions interested in participating in Project Aria can submit their proposals <a href="https://docs.google.com/forms/d/e/1FAIpQLSdA4Rba4nmsr18VkBcBCCwRnWLgBtX7KoCDH-uWfRdrBxTG1A/viewform">here</a>.</br>
        </tr>
      </table>

      <br>

  </body>

</html>
